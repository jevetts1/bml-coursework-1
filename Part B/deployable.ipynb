{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d284747b",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb770ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"./bml-component-data.csv\")\n",
    "\n",
    "# Scale time column\n",
    "data[\"timestamp\"] /= 10000\n",
    "data = data.drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0071a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(array, target_length):\n",
    "    \"\"\"Pads 1D array to target length using -1 constant as padding.\"\"\"\n",
    "\n",
    "    n_pad = target_length - array.shape[0]\n",
    "    return np.pad(array, (0, n_pad), mode=\"constant\", constant_values=[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f24a00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all values from each CX into one row and put timestamps and efficiencies into np arrays\n",
    "data_grouped = data.groupby([\"ID\"]).agg(list)\n",
    "data_grouped = data_grouped.map(np.array)\n",
    "\n",
    "# Each row is exactly one CX\n",
    "x = list(data_grouped[\"timestamp\"])\n",
    "y = list(data_grouped[\"efficiency\"])\n",
    "\n",
    "# Rows are ragged (rows aren't all the same length) so padding is required\n",
    "max_obs = max([len(row) for row in y])\n",
    "\n",
    "x_padded = np.array([pad(row, max_obs) for row in x])\n",
    "y_padded = np.array([pad(row, max_obs) for row in y])\n",
    "\n",
    "# Generate mask (True for actual values, False for padded values)\n",
    "mask = x_padded != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3e2c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate M1 to M5 arrays. Each M value is the same for all measurements within a CX component\n",
    "M_df = data.drop_duplicates(subset=[\"ID\"])\n",
    "\n",
    "# M[0] is all M1 values, M[1] is all M2 values etc.\n",
    "M = np.array([M_df[\"M1\"], M_df[\"M2\"], M_df[\"M3\"], M_df[\"M4\"], M_df[\"M5\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a987a",
   "metadata": {},
   "source": [
    "### Deployable Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7957500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro as npr\n",
    "import numpyro.distributions as dist\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "\n",
    "class DeployableModel:\n",
    "    def __init__(self, samples, m):\n",
    "        self.samples = samples\n",
    "        self.m = m\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(cls, t, y, m, mask):\n",
    "        def model(t, y, m, mask):\n",
    "            sigma = npr.sample(\"sigma\", dist.HalfNormal(1))\n",
    "\n",
    "            # Generate u_i and v_i for all CX components\n",
    "            with npr.plate(\"cx-component\", t.shape[0]):\n",
    "                u = npr.sample(\"u\", dist.Normal(90, 10))\n",
    "                v = npr.sample(\"v\", dist.Normal(5, 5))\n",
    "\n",
    "            # Generate a weight for each M component\n",
    "            with npr.plate(\"m\", m.shape[0]):\n",
    "                w = npr.sample(\"w\", dist.Normal(0, 1))\n",
    "\n",
    "            # Make predictions of f_i(t) then sample from normal dist with variance sigma to account for noise\n",
    "            with npr.plate(\"observations\", t.shape[1]):\n",
    "                with npr.handlers.mask(mask=mask):\n",
    "                    m_sum = -(v + jnp.matmul(w, m))\n",
    "                    f = u[:, jnp.newaxis] * jnp.exp(m_sum[:, jnp.newaxis] * t)\n",
    "                    npr.sample(\"obs\", dist.Normal(f, sigma), y)\n",
    "        \n",
    "        nuts_kernel = NUTS(model)\n",
    "        mcmc = MCMC(nuts_kernel, num_warmup=500, num_samples=1000)\n",
    "        rng_key = random.PRNGKey(0)\n",
    "        mcmc.run(rng_key, t=t, y=y, m=m, mask=mask)\n",
    "\n",
    "        return cls(mcmc.get_samples(), m)\n",
    "    \n",
    "    def inference(self, component: int, t: float):\n",
    "        t /= 10_000\n",
    "        u = self.samples[\"u\"][:, component] # 1000, \n",
    "        v = self.samples[\"v\"][:, component] # 1000, \n",
    "        w = self.samples[\"w\"]               # 1000, 5\n",
    "\n",
    "        m_sum = -(v + jnp.matmul(w, self.m[: ,component]))\n",
    "        f = u * jnp.exp(m_sum * t)\n",
    "\n",
    "        results = {\n",
    "            \"mean\": jnp.mean(f, axis=0), \n",
    "            \"5th_percentile\": jnp.percentile(f, 5, axis=0), \n",
    "            \"95th_percentile\": jnp.percentile(f, 95, axis=0)\n",
    "        }\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ea902e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayde\\AppData\\Local\\Temp\\ipykernel_12000\\2283172925.py:36: UserWarning: Missing a plate statement for batch dimension -2 at site 'obs'. You can use `numpyro.util.format_shapes` utility to check shapes at all sites of your model.\n",
      "  mcmc.run(rng_key, t=t, y=y, m=m, mask=mask)\n",
      "sample: 100%|██████████| 1500/1500 [00:10<00:00, 139.42it/s, 255 steps of size 1.98e-02. acc. prob=0.93]\n"
     ]
    }
   ],
   "source": [
    "model = DeployableModel.from_data(x_padded, y_padded, M, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b93d0f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': Array(21.530245, dtype=float32),\n",
       " '5th_percentile': Array(17.882442, dtype=float32),\n",
       " '95th_percentile': Array(25.311098, dtype=float32)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inference(10, 4000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
